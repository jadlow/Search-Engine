/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.luence.app;

import org.apache.lucene.analysis.en.EnglishAnalyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.*;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.NIOFSDirectory;

import java.io.IOException;
import java.io.File;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashSet;
import java.util.List;

/**
 * refer to <a href="https://www.lucenetutorial.com/lucene-in-5-minutes.html"/>
 */
public class App {
    private static List<String> stopwords;

    public static String removeStopwords(String input, HashSet<String> stopwords) {
        String[] words = input.split("\\s+");

        StringBuilder resultBuilder = new StringBuilder();

        for (String word : words) {
            if (!stopwords.contains(word.toLowerCase())) {
                resultBuilder.append(word).append(" ");
            }
        }

        // Convert the StringBuilder to a string and trim trailing spaces
        String result = resultBuilder.toString().trim();

        return result;
    }

    private static void addDoc(IndexWriter w, String seq_id, String med_id, String source, String mesh, String title, String pub_type, String ab, String author) throws IOException {
        Document doc = new Document();
        doc.add(new StringField("seq_id", seq_id, Field.Store.YES));
        doc.add(new StringField("med_id", med_id, Field.Store.YES));
        doc.add(new TextField("mesh", mesh, Field.Store.YES));
        /*splits text into strings (each string in text is an index*/
        doc.add(new TextField("title", title, Field.Store.YES));
        doc.add(new StringField("pub_type", pub_type, Field.Store.YES));
        doc.add(new TextField("ab", ab, Field.Store.YES));
        doc.add(new StringField("author", author, Field.Store.YES));
        /*treats entire string as an index*/
        doc.add(new StringField("source", source, Field.Store.YES));
        /*choose minimum size field to contain information and speed up query*/
        w.addDocument(doc);
    }

    public static void main(String[] args) throws IOException, ParseException {
        // specify "custom" or "baseline"
        String rankingAlgorithm = "custom";
        IndexWriterConfig config = null;
        if (rankingAlgorithm == "custom"){
            EnglishAnalyzer analyzer = new EnglishAnalyzer();
            config = new IndexWriterConfig(analyzer);
        }else{
            StandardAnalyzer analyzer = new StandardAnalyzer();
            config = new IndexWriterConfig(analyzer);
        }
        Directory index = new NIOFSDirectory(Paths.get("C:\\Users\\jacob\\Desktop\\CSE272\\CSE272_UCSC_Spring\\HW1\\java\\"+ rankingAlgorithm +"Index"));
        String content = Files.readString(new File("C:\\Users\\jacob\\Desktop\\CSE272\\CSE272_UCSC_Spring\\HW1\\java\\ohsumed.88-91").toPath(), StandardCharsets.UTF_8);

        // Split input into individual documents
        String[] documents = content.split("(?m)^\\.I\\s");

        // Initialize ArrayLists for each document field
        ArrayList<String> seq_ids = new ArrayList<>();
        ArrayList<String> med_ids = new ArrayList<>();
        ArrayList<String> sources = new ArrayList<>();
        ArrayList<String> meshes = new ArrayList<>();
        ArrayList<String> titles = new ArrayList<>();
        ArrayList<String> pub_types = new ArrayList<>();
        ArrayList<String> abs = new ArrayList<>();
        ArrayList<String> authors = new ArrayList<>();

        HashSet<String> stopwords = new HashSet<>(Arrays.asList(
                "a", "an", "and", "are", "as", "at", "be", "by", "for", "from",
                "has", "in", "is", "it", "its", "of", "on", "that", "the",
                "to", "was", "were", "will", "with", "he", "him", "his", "himself",
                "she", "her", "hers", "herself", "they", "them", "themselves", "theirs",
                "my", ",", ";", "*", "/"
        ));

        // Parse each document and store the fields in ArrayLists
        // handle incomplete documents **************************
        // Parse each document and store the fields in ArrayLists
        for (String doc : documents) {
            String[] fields = doc.split("(?m)^\\.(?!I)"); // split by any field except .I
            if (fields.length < 7) continue; // skip if any of the required fields is missing
            String seq_id = fields[0].trim();
            String med_id = "";
            String source = "";
            String mesh = "";
            String title = "";
            String pub_type = "";
            String ab = "";
            String author = "";
            String[] fields2 = Arrays.copyOfRange(fields, 1, fields.length);
            for (String field : fields2){
                String first_char = field.substring(0,1);
                switch (first_char){
                    case "U":
                        med_id = field.substring(2).trim();
                        break;
                    case "S":
                        source = field.substring(2).trim();
                        break;
                    case "M":
                        mesh = field.substring(2).trim();
                        break;
                    case "T":
                        title = field.substring(2).trim();
                        break;
                    case "P":
                        pub_type = field.substring(2).trim();
                        break;
                    case "W":
                        if (rankingAlgorithm == "custom"){
                            ab = removeStopwords(field.substring(2).trim(), stopwords);
                        }
                        else{
                            ab = field.substring(2).trim();
                        }
                        break;
                    case "A":
                        author = field.substring(2).trim();
                        break;
                }
            }
            seq_ids.add(seq_id);
            med_ids.add(med_id);
            sources.add(source);
            meshes.add(mesh);
            titles.add(title);
            pub_types.add(pub_type);
            abs.add(ab);
            authors.add(author);
        }

        try (IndexWriter w = new IndexWriter(index, config)) {
            for (int i = 0; i < seq_ids.size(); i++) {
//                System.out.println("Seq_id " + seq_ids.get(i));
//                System.out.println("Med_id: " + med_ids.get(i));
//                System.out.println("Source: " + sources.get(i));
//                System.out.println("Mesh: " + meshes.get(i));
//                System.out.println("Title: " + titles.get(i));
//                System.out.println("Pub_type: " + pub_types.get(i));
//                System.out.println("Abstract: " + abs.get(i));
//                System.out.println("Authors: " + authors.get(i));
//                System.out.println();
                addDoc(w, seq_ids.get(i), med_ids.get(i), sources.get(i), meshes.get(i), titles.get(i), pub_types.get(i), abs.get(i), authors.get(i));
            }
        }
    }
}
